{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H1_data = np.genfromtxt('H1_times.csv')\n",
    "L1_data = np.genfromtxt('L1_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "1\n",
      "0\n",
      "1\n",
      "2\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(H1_data[np.where(H1_data[:,9] == 1)]))\n",
    "print(len(H1_data[np.where(H1_data[:,10] == 1)]))\n",
    "print(len(H1_data[np.where(H1_data[:,11] == 1)]))\n",
    "\n",
    "print(len(L1_data[np.where(L1_data[:,9] == 1)]))\n",
    "print(len(L1_data[np.where(L1_data[:,10] == 1)]))\n",
    "print(len(L1_data[np.where(L1_data[:,11] == 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using multilabels, with i = 0 = cbc,\n",
    "#                           = 1 = burst,\n",
    "#                           = 2 = stoch,\n",
    "#                           = 3 = terrestrial\n",
    "training = np.array([])\n",
    "target = np.array([])\n",
    "n_terr = 0\n",
    "for event in H1_data:\n",
    "    if (event[9] == 1 or event[10] == 1 or event[11] == 1):\n",
    "        if (len(training) == 0):\n",
    "            training = np.array([event[2],event[3],event[4],event[5]])\n",
    "            target = np.array([int(event[9]),int(event[10]),int(event[11]),0])\n",
    "        else:\n",
    "            training = np.vstack((training,np.array([event[2],event[3],event[4],event[5]])))\n",
    "            target = np.vstack((target,np.array([int(event[9]),int(event[10]),int(event[11]),0])))\n",
    "        \n",
    "        continue # not counting hardware injections as terrestrial\n",
    "\n",
    "    \n",
    "    b = event[0] - 0.1\n",
    "    e = event[1] + 0.1\n",
    "    \n",
    "    # find H1 events whose beginings and ends do not overlap with L1 events\n",
    "    b_novr = len(np.where((b > L1_data[:,0]) & (b < L1_data[:,1]))[0]) == 0\n",
    "    e_novr = len(np.where((e > L1_data[:,0]) & (e < L1_data[:,1]))[0]) == 0\n",
    "    \n",
    "    if (b_novr and e_novr and n_terr < 200):\n",
    "        if (len(training) == 0):\n",
    "            training = np.array([event[2],event[3],event[4],event[5]])\n",
    "            target = np.array([0,0,0,1])\n",
    "        else:\n",
    "            training = np.vstack((training,np.array([event[2],event[3],event[4],event[5]])))\n",
    "            target = np.vstack((target, np.array([0,0,0,1])))\n",
    "        n_terr += 1\n",
    "        \n",
    "n_terr = 0            \n",
    "for event in L1_data:\n",
    "    if (event[9] == 1 or event[10] == 1 or event[11] == 1):\n",
    "        if (len(training) == 0):\n",
    "            training = np.array([event[2],event[3],event[4],event[5]])\n",
    "            target = np.array([int(event[9]),int(event[10]),int(event[11]),0])\n",
    "        else:\n",
    "            training = np.vstack((training,np.array([event[2],event[3],event[4],event[5]])))\n",
    "            target = np.vstack((target,np.array([int(event[9]),int(event[10]),int(event[11]),0])))\n",
    "        \n",
    "        continue # not counting hardware injections as terrestrial\n",
    "\n",
    "    \n",
    "    b = event[0]\n",
    "    e = event[1]\n",
    "    \n",
    "    # find H1 events whose beginings and ends do not overlap with L1 events\n",
    "    b_novr = len(np.where((b > H1_data[:,0]) & (b < H1_data[:,1]))[0]) == 0\n",
    "    e_novr = len(np.where((e > H1_data[:,0]) & (e < H1_data[:,1]))[0]) == 0\n",
    "    \n",
    "    if (b_novr and e_novr and n_terr < 200):\n",
    "        if (len(training) == 0):\n",
    "            training = np.array([event[2],event[3],event[4],event[5]])\n",
    "            target = np.array([0,0,0,1])\n",
    "        else:\n",
    "            training = np.vstack((training,np.array([event[2],event[3],event[4],event[5]])))\n",
    "            target = np.vstack((target, np.array([0,0,0,1])))\n",
    "        n_terr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale data for mlp\n",
    "scaler = StandardScaler()  \n",
    "\n",
    "scaler.fit(training)\n",
    "train_scale = scaler.transform(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split for training and testing\n",
    "dat_train, dat_test, tar_train, tar_test = train_test_split(train_scale, target, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MLP params\n",
    "hidden = (3,)\n",
    "activ = 'logistic'\n",
    "solver = 'lbfgs'\n",
    "lrn = 'adaptive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': array([  1.00000e-01,   1.00000e-02,   1.00000e-03,   1.00000e-04,\n",
       "         1.00000e-05,   1.00000e-06]), 'activation': ['logistic'], 'solver': ['lbfgs'], 'learning_rate': ['adaptive'], 'hidden_layer_sizes': [(3,)]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier()\n",
    "parameters = {'hidden_layer_sizes':[(3,)],'activation':['logistic'],'solver':['lbfgs'],'learning_rate':['adaptive'],'alpha':(10.0 ** -np.arange(1, 7))}\n",
    "clf = GridSearchCV(mlp, parameters)\n",
    "clf.fit(dat_train,tar_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=9.9999999999999995e-07,\n",
       "       batch_size='auto', beta_1=0.9, beta_2=0.999, early_stopping=False,\n",
       "       epsilon=1e-08, hidden_layer_sizes=(3,), learning_rate='adaptive',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = clf.best_params_['alpha']\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=hidden,activation=activ,solver=solver,learning_rate=lrn,alpha=alpha)\n",
    "mlp.fit(dat_train,tar_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(dat_test,tar_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(mlp, train_scale, target, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92 +/- 0.06\n",
      "[ 0.9245283   0.88679245  0.91509434  0.97169811]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f +/- %0.2f\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 21   3   0 400]\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(target, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(737, 4)\n",
      "(5091, 4)\n",
      "(424, 4)\n"
     ]
    }
   ],
   "source": [
    "H1 = np.array([H1_data[:,2],H1_data[:,3],H1_data[:,4],H1_data[:,5]]).T\n",
    "L1 = np.array([L1_data[:,2],L1_data[:,3],L1_data[:,4],L1_data[:,5]]).T\n",
    "print(H1.shape)\n",
    "print(L1.shape)\n",
    "print(train_scale.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "H1_labels = mlp.predict(H1)\n",
    "L1_labels = mlp.predict(L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0 737]\n",
      "[   0    0    0 5091]\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(H1_labels,axis=0))\n",
    "print(np.sum(L1_labels,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
